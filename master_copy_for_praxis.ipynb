{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mettalrose/DS2F_Workshop_Text_Mining/blob/master/master_copy_for_praxis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213a3be7-bddb-4a47-b580-86b3bfeae8fb",
      "metadata": {
        "id": "213a3be7-bddb-4a47-b580-86b3bfeae8fb"
      },
      "source": [
        "\n",
        "<h1>A Gentle DIY Introduction to Text Mining and Python for Humanities People</h1>\n",
        "\n",
        "<h2>A Computational Notebook</h2>\n",
        "    <h3> — Anuj Gupta </h3>\n",
        "    <h3> — Heather Froehlich </h3>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39467d6d-c58c-4ad1-b8e7-a46f88de4ec3",
      "metadata": {
        "id": "39467d6d-c58c-4ad1-b8e7-a46f88de4ec3"
      },
      "source": [
        "\n",
        "***Let's get started!***\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbbb4e14-5363-4361-a72b-f154706954f1",
      "metadata": {
        "id": "bbbb4e14-5363-4361-a72b-f154706954f1"
      },
      "source": [
        "\n",
        "<h3> OBJECTIVES </h3>\n",
        "\n",
        "\n",
        "\n",
        "1.   **ENCOUNTER**  the Natural Language Processing Toolkit (NLTK), a library for performing specific analyses of linguistic (i.e. textual) data\n",
        "2.   **PRACTICE** how to use computational methods that can help in analysing textual data using several common techniques: frequency distributions, data visualizations, and concordances.\n",
        "\n",
        "1.   **BRAINSTORM** how some of those techniques could be applied to your own work\n",
        "\n",
        "\n",
        "<h3> OVERVIEW </h3>\n",
        "\n",
        "\n",
        "1.   **TIME REQUIRED**: 90 mins\n",
        "\n",
        "2.   **MATERIALS NEEDED**:\n",
        "\n",
        "* <u>Google Collab Notebook</u>: A Google Collab notebook, which is what you are seeing right now, is an example of a \"computational notebook\" which is like a Google Docs environment for coding. You can run code in this interactive environment which is interspersed with textual commentary. You can also edit the code and write new code. Google Collab provides a user-friendly environment to practice coding.\n",
        "\n",
        "* <u> Web Browser</u>: Google Collab works best with Google Chrome, Mozilla Firefox, and Microsoft Edge. We recommend users to use their web browsers to avoid errors.\n",
        "\n",
        "* <u>A working internet connection </u>: This notebook runs on the internet so please make sure you have a decent internet connection.\n",
        "\n",
        "* <u> Accompanying article and videos</u>: While this notebook can definitely be used just on its own, we recommend using it in conjuction with its accompanying article in the journal Kairos which helps users understand the need for text-mining and also contains walkthrough videos to help you whenever you get stuck.\n",
        "\n",
        "3.   **PRE-REQUISITE KNOWLEDGE**:\n",
        "\n",
        "* <u>No prior programming knowledge needed</u>: We have designed this computational notebook assuming that our readers do not have any prior knowledge or experience working with Python, any other computer programming language, or any kind of data at all.\n",
        "\n",
        "\n",
        "4. **SECTIONS IN THIS COMPUTATIONAL NOTEBOOK**:\n",
        "\n",
        "\n",
        "*   <u>Part 1: Basic Setup</u>: In this section, you will get a basic overview of how to use a Google Collab based computational notebook, basics of using the Python programming language, and an introduction to NLTK or the Natural Language Tool Kit (NLTK), a library for performing specific analyses of linguistic (i.e. textual) data.\n",
        "\n",
        "*   <u>Part 2: Text Mining Techniques </u>: In this section, you will learn several common text mining techniques: frequency distributions, dispersion plots, concordances, and collocation methods. We will provide you with code and sample data to practice these techniques on and also share iconic studies that utilize these techniques.\n",
        "\n",
        "*   <u>Part 3: Further Exploration </u>: In this final section, we will share a list of resources that you can puruse on your own to continue your learning journey in the world text-mining.  \n",
        "\n",
        "\n",
        "5. **HOW TO ENGAGE WITH THIS COMPUTATIONAL NOTEBOOK**:\n",
        "\n",
        "\n",
        "*  <u>Sequential Sections</u>: Each section of this notebook is designed to build upon the knowledge and information from the previous section. While it's recommended to experience the sections in sequence, you are welcome to use individual sections independently if that better aligns with your objectives.\n",
        "\n",
        "*  <u>Stepping away</u>: If you step away from the computer, it is possible that the notebook might stop functioning if kept idle for a long time. If that happens, simply fresh the page or open the notebook again.\n",
        "\n",
        "*  <u>Saving Progress</u>: Keep in mind that this notebook will not automatically save your progress. If you stop in the middle, you will need to start again from the top. Alternatively, if you want to save your progress, you can simply save a version of this notebook in your Google Drive.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a24565a3-3c75-4828-a9df-cc75224a86b0",
      "metadata": {
        "id": "a24565a3-3c75-4828-a9df-cc75224a86b0"
      },
      "source": [
        "<h1> Part 1: Basic Setup </h1>\n",
        "\n",
        "<p>In this section, you will get a basic overview of how to use a Google Collab based computational notebook, basics of using the Python programming language, and an introduction to NLTK or the Natural Language Tool Kit (NLTK) (Bird et al., 2019), a library for performing specific analyses of linguistic (i.e. textual) data.  </p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1: What is Google Collab?**\n",
        "\n",
        "What you see on your screens is something called a Google Collab Computational Notebook. Think of this as a Google Docs for coding. In a computational notebook, you can write computer code and run it without going into a command line prompt on your own computer, which is where people historically wrote computer code. You can also invite other people to collaborate on your work with you. Importantly, any code you run here lives solely in your browser, though once you get comfortable working with scripting languages, you may want to learn how to execute these on your own in your own command line prompt. For now though, lets use this Google Collab environment itself. You have already overcome the first hurdle, by loading this Google Collab notebook!"
      ],
      "metadata": {
        "id": "_6XBzgS-xZED"
      },
      "id": "_6XBzgS-xZED"
    },
    {
      "cell_type": "markdown",
      "id": "0eb11dba-25fd-4cc0-b8b4-8fb60b0ec14e",
      "metadata": {
        "id": "0eb11dba-25fd-4cc0-b8b4-8fb60b0ec14e"
      },
      "source": [
        "**1.2: What is a code cell in Google Collab and how to run it?**\n",
        "<p> Google Collab contains two types of cells: text cells and code cells. A text cell is simply like the on you are currently reading where we can use HTML to write prose and format it. A code cell, on the other hand, what you can see below, is a special space where you can write, edit, or run pre-written code. <u>In a Google Collab notebook, code is primarily written in the programming language called \"Python\"</u>.\n",
        "\n",
        "When we say \"run\" code, we simply mean clicking on the ▶ button that appears on the left of a code cell when you hover over it. </p>\n",
        "\n",
        "Try to run the cell below that starts with the word \"print\" ! Just hover over the cell on play button or the ▶ button that appears to left of the cell. </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edb0f28a-b14e-4844-b8fb-5155467818f3",
      "metadata": {
        "id": "edb0f28a-b14e-4844-b8fb-5155467818f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ad3086-ebca-475a-ec32-4e44c713f6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi! Try to print me.\n"
          ]
        }
      ],
      "source": [
        " print(\"Hi! Try to print me.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Accepting Warnings**\n",
        "\n",
        "The first time you run this cell, you'll notice a warning appear asking you to be cautious when running computational notebooks from the internet. That is an important caution that you should keep in mind when running notebooks whose authenticity and credibility you are unsure of. Since the current notebook has been peer reviewed, you can safely click on \"Run Anyway\"."
      ],
      "metadata": {
        "id": "Zl337ETO0OBl"
      },
      "id": "Zl337ETO0OBl"
    },
    {
      "cell_type": "markdown",
      "id": "369cfe4e-65b0-48cc-9224-552e10b01114",
      "metadata": {
        "id": "369cfe4e-65b0-48cc-9224-552e10b01114"
      },
      "source": [
        "<b>1.4: Reading Results after Running Code</b>\n",
        "If all goes well, i.e. if your code has run successfully, you should see a little green tick mark next to the code cell along with a time reference indicating how long it took to run that code and finally the results of what running that code did at the bottom of your code cell.\n",
        "\n",
        "Congratulations. You've just run your first ever code cell. In this code, we simply told the computer to print or show us as the output whatever sentence was written within the bracket. If your code worked properly, you should be seing the sentence \"Hi! Try to print me\" below the code cell.\n",
        "\n",
        "Notice, that the input code cell, which was once represented as:\n",
        "\n",
        "`[ ]:`\n",
        "\n",
        "has now become:\n",
        "\n",
        "`[1]:`\n",
        "\n",
        "This means your code in that particular cell has run, and it was the first code cell that you ran (hence the `1`). If you run the same block multiple times, you'll see that this number will keep on increasing.\n",
        "\n",
        "***\n",
        "\n",
        "This code ran quickly. However, sometimes it might take some time. If your code is still running it'll look like rotating circle:\n",
        "\n",
        "![Screenshot 2023-10-09 at 12.06.02 PM.png](data:image/png;base64,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)\n",
        "\n",
        "That rotating circle means this cell of code is still running. Be patient whenever you see this sign."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> 1.5 Understanding Errors </b>\n",
        "\n",
        "Python is very good at noticing mistakes. These mistakes can either be a typo that we make or some error in the logic of our commands. Whenever we make such mistakes, Python tells us what we have done by displaying an error message. It is useful to learn how to read those messages so we can correct our mistakes.\n",
        "\n",
        "In the example you see below, if you spell \"print\" as \"drint\", see what error message gets displayed when you run the cell."
      ],
      "metadata": {
        "id": "hlnd2BQo1vXr"
      },
      "id": "hlnd2BQo1vXr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5be45595-b913-484b-889c-3e14358acbd2",
      "metadata": {
        "id": "5be45595-b913-484b-889c-3e14358acbd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "4dc4de4f-07f2-4c4d-eb73-507cc945eec0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d7035dfcca46>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"this will not print because of a syntax error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'drint' is not defined"
          ]
        }
      ],
      "source": [
        "drint(\"this will not print because of a syntax error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error message should tell you something like \"name 'drint' is not defined. When you find out what the error is, you can simply correct it. Go to the code cell again and change the word \"drint\" to \"print\" and re-run it. It should work fine now."
      ],
      "metadata": {
        "id": "vu516VrR2NHI"
      },
      "id": "vu516VrR2NHI"
    },
    {
      "cell_type": "markdown",
      "id": "bfb3cb36-bc92-4e76-9bff-1f7664e54fd7",
      "metadata": {
        "tags": [],
        "id": "bfb3cb36-bc92-4e76-9bff-1f7664e54fd7"
      },
      "source": [
        "<b> 1.6 What is Python? </b>\n",
        "\n",
        "Python is one of the many computer languages that exist in the world. Programming languages are not entirely like natural languages, but they allow us to communicate with our computers to do increasingly advanced things.\n",
        "\n",
        "Python has become very popular in recent years and is used widely today because:\n",
        "* Lots of resources available online to learn it\n",
        "* Compared to many other programming languages, it is closest in syntax and lexicon to human languages like English, which makes it easier for English speakers to use"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6917edde-2741-4fed-967f-7b86f8d01c8e",
      "metadata": {
        "id": "6917edde-2741-4fed-967f-7b86f8d01c8e"
      },
      "source": [
        "<b> 1.7 Writing programs in Python </b>\n",
        "\n",
        "<p> When we write code in Python, we are simply writing commands in a language that our computer understands. Essentially we are telling the computer to do something for us.\n",
        "\n",
        "For example, let's use Python to tell the computer to do some addition for us. Observe carefully the syntax of the commands we write in the code cell below and run the cell to see what happens with these commands: </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f9d6fc-f401-47fa-945c-866f86ef958a",
      "metadata": {
        "id": "41f9d6fc-f401-47fa-945c-866f86ef958a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505c9e17-2205-49c4-d47c-90de83c2b684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the sum of these numbers is  12\n"
          ]
        }
      ],
      "source": [
        "first_number = 5\n",
        "second_number = 7\n",
        "sum = first_number + second_number\n",
        "print(\"the sum of these numbers is \",sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e938563-9fa3-4e0c-9533-c1b72338aed8",
      "metadata": {
        "id": "9e938563-9fa3-4e0c-9533-c1b72338aed8"
      },
      "source": [
        "<p>Excellent! What we did here is simply to create variables called \"first_number\" and \"second_number\" and then to store certain data in them (the numbers 5 and 7). Then we created a new variable called \"sum\" and told the computer that we want to store the sum of those first two variables in that third variable. Finally, we asked the computer to print or display whatever is stored in that third variable called \"sum\" along with some text \"the sum of these numbers is \" in the display space.\n",
        "\n",
        "If you understand how to use this basic syntax to tell your computer how to store things and how you want to create complex relationships between those stored things, you can do amazing and powerful things. Everything we use on a computer, including social media, netflix, data science, AI, games, sending rockets to the moon etc. — everything has been built using these rudimentary building blocks. Its all about building more and more complexity to this basic structure. Amazing isn't it? </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7309039-de44-47fa-95c6-fd7891ef4b90",
      "metadata": {
        "id": "c7309039-de44-47fa-95c6-fd7891ef4b90"
      },
      "source": [
        "<b> 1.8 Understanding functions in Python </b>\n",
        "<p> Rarely do we have to start from scratch when we encounter a programming language. Instead, we can call up bits of code written by other people and supplement it with what our particular needs are. Each bit of code written by someone else that we can use is called a \"function\". For example, in the above cells we just wrote code for a \"sum\" function that could add two numbers together. If we anticipate using this code again, we can save in the form of a function and save it. Or we can also search online and find functions already created and saved by members of the Python development community.\n",
        "    \n",
        "<b>Function</b> = <u>collection of code that performs a particular role and can be recycled to suit the needs of different coders</u>.\n",
        "    \n",
        "Let's what this looks like in practice. Observe what is happening in the code cell below:</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a0cff8f-f6dd-4cde-af02-ae156e282f7b",
      "metadata": {
        "id": "1a0cff8f-f6dd-4cde-af02-ae156e282f7b"
      },
      "outputs": [],
      "source": [
        "text = \"i am a human being trying to learn Python\"\n",
        "count =len(text)\n",
        "print(\"the total number of characters in my text is \" + str(count))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeaa6111-50aa-4346-941d-7bb87da34da9",
      "metadata": {
        "id": "aeaa6111-50aa-4346-941d-7bb87da34da9"
      },
      "source": [
        "<p>Here we have used a function called \"len\" which means \"length\" and it basically just calculates the number of characters (alphabets, numbers, punctuation, spaces etc.) that we have stored in a variable. People who created Python wrote the code for this function and simply saved it using the abbreviation \"len\" so we can just type that instead of having to type the corresponding code everytime. Programmers like being efficient; shortened forms like this are common as they reduce the amount of typing someone will have to do</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68022347-6c68-43b5-a28a-182869b2d756",
      "metadata": {
        "id": "68022347-6c68-43b5-a28a-182869b2d756"
      },
      "source": [
        "<p> Just like this \"len\" function there are millions of functions for which people across the world have written code so that we don't need to reinvent the wheel each time. We can simply recycle these functions for our purposes and stand on the shoulders of giants, kind of like how in academic writing we use ideas from other scholars.\n",
        "\n",
        "To learn about some of these basic functions, you can visit this link:</p> https://docs.python.org/3/library/functions.html\n",
        "\n",
        "<b>Citation Norms</b>: Unlike in academi writing, to the best of our knowledge, citation norms in coding aren't as formally defined. It is always a good practice, however, to cite the functions that we borrow from others. As we will see below when we use functions from the NLTK library, usually the sources that we get the functions from have information about how to cite them. We'll discuss this in more detail below. For now, let's try out some functions in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35ff6791-df67-45fd-8ef8-774706f33cbc",
      "metadata": {
        "tags": [],
        "id": "35ff6791-df67-45fd-8ef8-774706f33cbc"
      },
      "source": [
        "\n",
        "\n",
        "<b>Exercise 1: Trying out Python Functions</b>\n",
        "\n",
        "In the cells below, first replace the text that says \"input your text here\" with any sentence you like and run it. Make sure to run this cell first. Then run second cell that follows to see how many characters it contains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61738c78-a418-454b-aaf5-e7816b164f55",
      "metadata": {
        "id": "61738c78-a418-454b-aaf5-e7816b164f55"
      },
      "outputs": [],
      "source": [
        "my_text = \"input your text here\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf398747-bd14-4ed4-8bbe-51916e02cbd8",
      "metadata": {
        "id": "bf398747-bd14-4ed4-8bbe-51916e02cbd8"
      },
      "outputs": [],
      "source": [
        "my_count =len(my_text)\n",
        "print(\"the total number of characters in my text is \" + str(my_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4a88fba-2674-4fee-b05d-7958d98372bd",
      "metadata": {
        "id": "d4a88fba-2674-4fee-b05d-7958d98372bd"
      },
      "source": [
        "<b> 1.9: Understanding libraries in Python </b>\n",
        "\n",
        "<p> Now if people simply wrote individual functions and uploaded them on various websites, it could create chaos because there would be billions of functions just floating around in the world, make it very difficult for us to see which functions are useful for us to learn for what purpose. So to create some method in this madness, people have come up with the idea of \"libraries\" which are simply collections or bundles of functions clubbed together based on their roles and the domains in which they are useful. Sometimes people might use the words \"libraries\" and \"packages\" inter-changeably.  \n",
        "    \n",
        "<b> Library</b> = <u>bundles of functions that perform similar roles</u>.  \n",
        "\n",
        "Let's see what this looks like in practice"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17bff814-ec36-4d3c-a9ee-384bcbfdf3ab",
      "metadata": {
        "id": "17bff814-ec36-4d3c-a9ee-384bcbfdf3ab"
      },
      "source": [
        "<b> 1.10: Learning about the NLTK Library </b>\n",
        "\n",
        "<p> \"NLTK\" or the Natural Language ToolKit (© 2023, NLTK Project) is a specific Python library created by these amazing folks (https://www.nltk.org/team.html). It \"is a leading platform for building Python programs to work with human language data\" (Bird et al., 2019). It contains lots of functions that can help us do text mining. We will be using this library throughout.\n",
        "\n",
        "<b>Note on citation:</b> If you visit the website for NLTK (https://www.nltk.org/), you will see that they specify how they would like us to cite NLTK whenever we use it: Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python. O’Reilly Media Inc. Thus, when write code that uses functions from the NLTK library, and when we write papers that uses such code, it is generally a good practice to write (Bird et al., 2019) as in-text citation and to give a full bibliographic citation towards the end. Unliike in academic writing though, such citations are not mentioned in each line of code. Rather they are mentioned the first time they are referenced in code as well as in a paper to give attributions to the owners of the library.Whenever you use libraries created by other coders, it is good practice to check their licensing information and cite them accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> 1.11: Download the NLTK Library </b>\n",
        "\n",
        "To use the NLTK library, we need to first download it. When you run the code cell below, you should see a pink box with lots sentences that start with \"Downloading\". Let it run. You'll know its complete when you see \"Done downloading collection book\" appear at the end of the pink box. What is happening here is that certain corpora from the NLTK servers are being downloaded to a local cloud version within Google Collab for you to explore and analyse. </p>"
      ],
      "metadata": {
        "id": "cq7ouejmEp_S"
      },
      "id": "cq7ouejmEp_S"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8bf5d39-c757-4b0e-8ee2-4a481bc63184",
      "metadata": {
        "id": "b8bf5d39-c757-4b0e-8ee2-4a481bc63184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc3de00-d4c0-40fd-cf3e-f28a0137b62d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"book\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fd4539-31ca-49f3-9dad-142a6de9b17c",
      "metadata": {
        "id": "94fd4539-31ca-49f3-9dad-142a6de9b17c"
      },
      "source": [
        "<b> 1.12 Exploring the NLTK Library </b>\n",
        "\n",
        "The NLTK library essentially contains two primary things:\n",
        "* <b>Corpora</b>: In linguistic terms, a \"corpus\" (plural: corpora) refers to a systematically organized collection of texts, often used for linguistic research and analysis. These texts can range from literary works to transcriptions of spoken language. The NLTK library includes a wide array of corpora, such as literary texts, linguistic datasets, and other textual resources, facilitating diverse linguistic and computational research.\n",
        "\n",
        "* <b>Text Mining Functions</b>: These are a suite of functions provided by the NLTK to facilitate the analysis, processing, and exploration of textual data. This encompasses various tasks like frequency counts of words etc. among others. These functions are not limited to the corpora included within NLTK; they can also be applied to any external text data that users might want to analyze.\n",
        "\n",
        "To learn more about what all the NLTK library contains, we encourage you to visit their website (https://www.nltk.org/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2fc1bd3-f659-4d68-bd08-8247394652f9",
      "metadata": {
        "id": "f2fc1bd3-f659-4d68-bd08-8247394652f9"
      },
      "source": [
        "<b> 1.13 Loading corpora </b>\n",
        "<p> As explained in section 1.12 above, a systematically organized collection of texts, often used for linguistic research and analysis. The NLTK library contains some in-built corpora that we can use use to try out NLTK's text-mining functions or functions that help us analyse process and explore textual data.\n",
        "\n",
        "Let's download a few in-built NLTK corpora by clicking on the code cell below. It might take a few seconds to run. You'll know its done running when you see this sentence appear at the bottom:\"text9: The Man Who Was Thursday by G . K . Chesterton 1908\".\n",
        "\n",
        "<b>Important Note</b>: We encourage you to not worry too much about the specific coding syntax we are using to do this as this workshop is not so much about learning the particular syntax, but instead about gaining familiarity what what it can do. That said, we are confident that you can parse out some of the commands provided -- what might the below code block be asking?</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2b413bbd-3b1f-4abe-8714-c19d980032bf",
      "metadata": {
        "id": "2b413bbd-3b1f-4abe-8714-c19d980032bf"
      },
      "outputs": [],
      "source": [
        "from nltk.book import*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fcdb5b9-4bf2-4e5b-a4cb-25771b7a031f",
      "metadata": {
        "id": "1fcdb5b9-4bf2-4e5b-a4cb-25771b7a031f"
      },
      "source": [
        "<p> Using the command in the code cell above, NLTK makes available 9 of its most popular corpora available to us to explore and analyse. There is no particular reason why NLTK provides 9 and not 10 or 11 corpora through this command. It is just a randomly selected number of texts that it provides with this command. There are other commands through which we can access other kinds of corpora in NLTK. You can learn more about those here (https://www.nltk.org/book/ch02.html).\n",
        "\n",
        "As we can probably infer from the output above, Python has just downloaded 9 corpora, each of which represents a different kind of textual data from the English language. It has also stored them in variables ranging from text1 to text9. Each of these corpora is either a famous literary work (like text1 --> Moby Dick) or collection of important socio-political texts (like text4 --> a collection of the inaugural addresses given all American presidents till Bill Clinton) or a smaller subsection of web-based corpora (like text5 --> Chat Corpus is a collection of 10,567 posts collected from various online chat services); and text8 --> this is a collection of personal advertisements in newspapers.  \n",
        "\n",
        "For the purposes of this computational notebook, we will use just these nine corpora. </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204e8cfe-a5ab-4d5e-8311-54f9ab3f9423",
      "metadata": {
        "tags": [],
        "id": "204e8cfe-a5ab-4d5e-8311-54f9ab3f9423"
      },
      "source": [
        "<b> 1.14 Using NLTK Functions </b>\n",
        "\n",
        "<p> By now, I hope that you are familiar with what functions are. The NLTK has thousands of functions which help us do different kinds of text mining. Let's see how one of these functions called \"concordance\". Concordancing is a function that allows us to see a window of context in which key words that interest appear in the corpora of our choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fc297fac-77dd-4434-9498-39979e14ada6",
      "metadata": {
        "id": "fc297fac-77dd-4434-9498-39979e14ada6",
        "outputId": "410d54aa-8605-4c49-ac9d-158978685a89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 152 matches:\n",
            "linterable glasses ! EXTRACTS . \" And God created great whales .\" -- GENESIS . \n",
            " . \" That sea beast Leviathan , which God of all his works Created hugest that \n",
            " . A . D . 1668 . \" Whales in the sea God ' s voice obey .\" -- N . E . PRIMER .\n",
            " ' S CONVERSATIONS WITH GOETHE . \" My God ! Mr . Chace , what is the matter ?\" \n",
            "out me in the dark . \" Landlord , for God ' s sake , Peter Coffin !\" shouted I \n",
            " of the word , to the faithful man of God , this pulpit , I see , is a self - c\n",
            "orld . From thence it is the storm of God ' s quick wrath is first descried , a\n",
            "arliest brunt . From thence it is the God of breezes fair or foul is first invo\n",
            "ed over me a dismal gloom , While all God ' s sun - lit waves rolled by , And l\n",
            "r . \" In black distress , I called my God , When I could scarce believe him min\n",
            "htning shone The face of my Deliverer God . \" My song for ever shall record Tha\n",
            " joyful hour ; I give the glory to my God , His all the mercy and the power . N\n",
            "of the first chapter of Jonah --' And God had prepared a great fish to swallow \n",
            "lesson to me as a pilot of the living God . As sinful men , it is a lesson to u\n",
            "wilful disobedience of the command of God -- never mind now what that command w\n",
            "ard command . But all the things that God would have us do are hard for us to d\n",
            "ndeavors to persuade . And if we obey God , we must disobey ourselves ; and it \n",
            "ves , wherein the hardness of obeying God consists . \" With this sin of disobed\n",
            "n him , Jonah still further flouts at God , by seeking to flee from Him . He th\n",
            "n will carry him into countries where God does not reign , but only the Captain\n",
            "onah sought to flee world - wide from God ? Miserable man ! Oh ! most contempti\n",
            "at and guilty eye , skulking from his God ; prowling among the shipping like a \n",
            " and turns in giddy anguish , praying God for annihilation until the fit be pas\n",
            ". In all his cringing attitudes , the God - fugitive is now too plainly known .\n",
            "forced from Jonah by the hard hand of God that is upon him . \"' I am a Hebrew ,\n"
          ]
        }
      ],
      "source": [
        "text1.concordance(\"God\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3686aa-fba1-488b-8481-f8ac5ce2dc07",
      "metadata": {
        "id": "6d3686aa-fba1-488b-8481-f8ac5ce2dc07"
      },
      "source": [
        "<h1> Part 2: Text Mining Techniques </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>\n",
        "\n",
        "Now that we understand the basics, let's start exploring some popular text mining techniques. In this notebook, we are introducing you to frequency counts, bar graphs, dispersion plots, and concordance lines.\n",
        "\n",
        "There are ofcourse not the only kind of text-mining techniques. To go more in-depth into a wider range of techniques that are used in text-mining based research, we encourage you to explore Janicke et al. (2015), Jockers (2013), Aull (2017), Underwood (2017), and Walsh (2021).   \n",
        "\n",
        "</p>"
      ],
      "metadata": {
        "id": "D24oYIjbfE2y"
      },
      "id": "D24oYIjbfE2y"
    },
    {
      "cell_type": "markdown",
      "id": "0dee5cd9-4d13-426a-8e17-704804fcd4f5",
      "metadata": {
        "id": "0dee5cd9-4d13-426a-8e17-704804fcd4f5"
      },
      "source": [
        "\n",
        "       \n",
        "<b> 2.1: Technique Type: 1: Frequency Counts <b>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31e0590-4878-4112-8f22-d9565342b165",
      "metadata": {
        "id": "f31e0590-4878-4112-8f22-d9565342b165"
      },
      "source": [
        "<b> 2.1.1: What is \"frequency\" and why should we care? </b>\n",
        "\n",
        "<p> Counting the frequency of words in a text or corpus is one of the most basic text mining function that can be performed. Finding “high-frequency words [is] valuable because they have “aboutness”; they suggest what the overall textual object is about\" (Archer, 2009, p. 4). The frequency of words is “a relatively objective means of uncovering lexical salience/(frequency) patterns that invite—and frequently repay—further qualitative investigation\" (Archer, 2009, p.15).\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e553254e-e115-45a9-8bd7-63a8eaa80a83",
      "metadata": {
        "id": "e553254e-e115-45a9-8bd7-63a8eaa80a83"
      },
      "source": [
        "We can use a simple function called \"count\" to find the frequency or the number of times a word appears in a text. Let's see how it works by using Moby Dick (text1) as an example. Let's say that we might be interested in finding out more about the word \"God\" and how many times it appears in this text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d77f7f4e-0113-4bd8-8571-3e9bc8e10484",
      "metadata": {
        "id": "d77f7f4e-0113-4bd8-8571-3e9bc8e10484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18008eb-0a8d-4db6-b0b3-75ce83aab11e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Let's create code that will help us find the frequency of the word \"God\" in Moby Dick\n",
        "\n",
        "text1.count(\"God\")\n",
        "\n",
        "#In the line of code above, we first type the name of the variable where we saved the Moby Dick corpus. If you look at Section 1.13, you'll see it was text 1.\n",
        "#Next we add an in-built NLTK function called \"count\" to and in paranthesis and within double quotes we write the word whose frequency counts we want to see. In this case that is the word \"God\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454367d3-68b7-4864-9b2e-60bd467beb2a",
      "metadata": {
        "id": "454367d3-68b7-4864-9b2e-60bd467beb2a"
      },
      "source": [
        "This shows us that the word \"God\" appears 132 times in the book Moby Dick. How many times do you think it would appear in the Book of Genesis? More or less than in Moby Dick? Let's find out!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f7f8ba0-6807-4eb7-a64d-f35e906caeee",
      "metadata": {
        "id": "9f7f8ba0-6807-4eb7-a64d-f35e906caeee"
      },
      "source": [
        "    \n",
        "<b> Exercise 2: Trying out Frequency Counts </b>\n",
        "    \n",
        "Write code in the box below to find out how many times the word \"God\" appears in the Book of Genesis. Remember that in the corpus we downloaded, the Book of Genesis is called text3. (To refresh your memory about which variable contains which text from the corpora we downloaded, please refer to Section 1.13 above)\n",
        "\n",
        "<u>Hint</u>: Look at the code cell above and try to replicate that syntax here and just change \"text1\" to \"text3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef6d7a7-b718-453e-bfd2-13df73ffd9ad",
      "metadata": {
        "id": "5ef6d7a7-b718-453e-bfd2-13df73ffd9ad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "82f0c2f9-213d-42c0-8fba-3f75c4c6db19",
      "metadata": {
        "id": "82f0c2f9-213d-42c0-8fba-3f75c4c6db19"
      },
      "source": [
        "Excellent! Now this simple technique of counting frequency of different words can lead to many interesting insights.\n",
        "\n",
        "For example, things start to get interesting when we compare such frequencies across texts. Let's see how the frequency of the word \"God\" varies across the texts that we have.\n",
        "\n",
        "In the code below, we are creating 9 new variables named a,b,c,d,e,f,g,h,i and in each of them we are storing the total count of the word \"God\" in each of our 9 texts. Run the code cell below and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b6b3ad8a-9c42-48e6-bf04-bbee93212597",
      "metadata": {
        "id": "b6b3ad8a-9c42-48e6-bf04-bbee93212597"
      },
      "outputs": [],
      "source": [
        "a = text1.count(\"God\")\n",
        "b = text2.count(\"God\")\n",
        "c = text3.count(\"God\")\n",
        "d = text4.count(\"God\")\n",
        "e = text5.count(\"God\")\n",
        "f = text6.count(\"God\")\n",
        "g = text7.count(\"God\")\n",
        "h = text8.count(\"God\")\n",
        "i = text9.count(\"God\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17f5690c-541e-455c-a287-ebd9dfc5dbc4",
      "metadata": {
        "id": "17f5690c-541e-455c-a287-ebd9dfc5dbc4"
      },
      "source": [
        "What is happening in the code cell above is that for each text (text1, text2, text3, etc.) in our corpora, we have added code for an in-built NLTK function called \"count\", by including the \".count\" suffix. This tells the computer to first identify the source text, and then perform an action (in this case, to count something). We specify \"God\" in the parentheses, telling the computer what we want it to count. These are assigned to new variables that we are naming with individual letters (a, b, c, d, e, f...) with the equals sign, so that the entire function can be called up easily and quickly.\n",
        "\n",
        "As you might see when you run the code cell above, you get a list of numbers but on their own, they are difficult to comprehend. This is why, often such functions are supplemented with \"print statements\" that allow us to add explanatory text in the output. Run the code cell below and see what that does.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "49eae968-83ed-4aae-adea-1b3cc22f6a34",
      "metadata": {
        "id": "49eae968-83ed-4aae-adea-1b3cc22f6a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b460856-4a03-4516-c885-9b3b76df0b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency Distribution of the word God in the following texts:\n",
            "Moby Dick = 132\n",
            "Sense and Sensibility = 10\n",
            "The Book of Genesis = 231\n",
            "Inaugural Address Corpus =111\n",
            "Chat Corpus = 1\n",
            "Monty Python and the Holy Grail = 11\n",
            "Wall Street Journal = 1\n",
            "Personal Corpus = 0\n",
            "The Man Who Was Thursaday = 33\n"
          ]
        }
      ],
      "source": [
        "print (\"Frequency Distribution of the word God in the following texts:\")\n",
        "print(\"Moby Dick = \" + str(a))\n",
        "print(\"Sense and Sensibility = \" + str(b))\n",
        "print(\"The Book of Genesis = \" + str(c))\n",
        "print(\"Inaugural Address Corpus =\" + str(d))\n",
        "print(\"Chat Corpus = \" + str(e))\n",
        "print(\"Monty Python and the Holy Grail = \" + str(f))\n",
        "print(\"Wall Street Journal = \" + str(g))\n",
        "print(\"Personal Corpus = \" + str(h))\n",
        "print(\"The Man Who Was Thursaday = \" + str(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is happening in the code cell above is that we are using the \"print\" function for each of our corpora. With the first \"print\" statement, we are simply printing or displaying a title sentence that tells us what this analysis is doing. Each subsequent print statement then adds context by giving us the name of each text in our corpora and then displaying the count value of how many times the word \"God\" appears in each of them. Together, this entire output makes it easy to follow the results that the text-mining procedure of frequency count has produced for us.\n",
        "\n",
        "<b> What kind of inferences could we draw from this? </b>\n",
        "\n",
        "<b> Hint: </b> There can be many inferences that one might draw about what the different frequencies of the word \"God\" reveals to us about these texts and the cultures that they come from. Try to think of categories using which we can diffrentiate between texts in our corpus. What happens when we compare them based on their genre? What happens when we compare them based on their years of publication? What about their cultural contexts?\n",
        "\n",
        "While this might seem quite revealing, to make our inferences more robust, we need to ensure that our data are valid. Right now, we have counted pure frequencies of words but in order to compare them across texts, we need to have normalized frequencies."
      ],
      "metadata": {
        "id": "qRDFNvBes5T_"
      },
      "id": "qRDFNvBes5T_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> 2.1.2: Normalized Frequency Counts </b>\n",
        "\n",
        "Imagine if the word \"God\" appears 10 times in text1 and 5 times in text2. On the surface level it would make us infer that the word \"God\" is more important in textA right? However, what if text1 contains 10,000 words and text2 contains only 100 words. That would make the word \"God\" more relevant in textB right? This is why often researchers recommend that \"considering frequencies in terms of standardized percentages is often a more sensible way of making sense of data, particularly when comparisons between two or more datasets of different sizes are made\" (Baker, 2006, p.51).\n",
        "\n",
        "So to make our frequency results more robust, we calculate what is called \"normalized frequencies\" which are essentially standardized percentages that allow us to compare word frequencies across texts of differing lengths. The most common normalized frequency that you might be familiar with is a \"percentage\" where we divide the frequency of the word we are interested in with the total number of words in a corpus and then multiple that with 100. However, since many words that interest us in a text (especially infrequent ones) would have very tiny percentages, scholars often multiply with a larger number (like 1,000,000), to make the numbers more interpretable and avoid very small decimals. Normalized frequencies in textual data can thus be represented using values like FPM or frequencies per million (Bestgen, 2019)\n",
        "\n",
        "This can be done simply using this formula:\n",
        "\n",
        "<b>Normalized frequency of word w in text T (FPM) = (number of times word w appears in text T/ total number of words in text T)* 1000000 </b>\n",
        "\n"
      ],
      "metadata": {
        "id": "94NNmdTq6pT3"
      },
      "id": "94NNmdTq6pT3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do this, we need to first calculate the total number of words in each of our texts using the \"len\" or length function we learnt earlier."
      ],
      "metadata": {
        "id": "ps_o5a9B68Gm"
      },
      "id": "ps_o5a9B68Gm"
    },
    {
      "cell_type": "code",
      "source": [
        "#First lets get the total number of words in text1 and save it in a variable called \"text1_1en\" by which we simply mean that it stores length of text1.\n",
        "text1_len=len(text1)\n",
        "\n",
        "#Then lets print the value of the number stored in \"text1_len\"\n",
        "print(text1_len)"
      ],
      "metadata": {
        "id": "S6txV7gi69iC"
      },
      "id": "S6txV7gi69iC",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Exercise 3: Developing Normalized Frequencies </b>\n",
        "   \n",
        "Now you try.\n",
        "\n",
        "Try to find out total number of units in text2 in the box below.\n",
        "\n",
        "<b> Hint</b>: Copy the code from the code above and simply replace \"text1\" with \"text2\", and \"text1_len\" with another variable like \"text2_len\"\n"
      ],
      "metadata": {
        "id": "uvwSmKzkP68K"
      },
      "id": "uvwSmKzkP68K"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s3T4vhCfQLdd"
      },
      "id": "s3T4vhCfQLdd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good job! Now run the code cell below below which will find out the overall lengths of all the texts in our collection. To make it easy for us to remember what these variables do, we are naming them as \"a_len\" which essentially means the length or total number of words in text1.\n"
      ],
      "metadata": {
        "id": "etLSh4rtQL4J"
      },
      "id": "etLSh4rtQL4J"
    },
    {
      "cell_type": "code",
      "source": [
        "text1_len=len(text1)\n",
        "text2_len=len(text2)\n",
        "text3_len=len(text3)\n",
        "text4_len=len(text4)\n",
        "text5_len=len(text5)\n",
        "text6_len=len(text6)\n",
        "text7_len=len(text7)\n",
        "text8_len=len(text8)\n",
        "text9_len=len(text9)"
      ],
      "metadata": {
        "id": "QsaBEgRzQZTk"
      },
      "id": "QsaBEgRzQZTk",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code above, we simply saved the total number of words. Lets now print them by adding some explanatory text along with it. Run the code cell below to do this.\n",
        "\n",
        "By now, you should be familiar with how the \"print\" function allows us to display any text that we want by putting it in double quotes, and the values of any variables we want by putting the name of the variables without any quotes around it."
      ],
      "metadata": {
        "id": "ZK7r3dgaQh4p"
      },
      "id": "ZK7r3dgaQh4p"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The length of words (including punctuations) in Moby Dick is \",text1_len)\n",
        "print(\"The length of words (including punctuations) in Sense & Sensibility is \",text2_len)\n",
        "print(\"The length of words (including punctuations) in the Book of Genesis is \",text3_len)\n",
        "print(\"The length of words (including punctuations) in the Inaugural Address Corpus is \",text4_len)\n",
        "print(\"The length of words (including punctuations) in the Chat Corpus is \",text5_len)\n",
        "print(\"The length of words (including punctuations) in Monty Python and the Holy Grail is \",text6_len)\n",
        "print(\"The length of words (including punctuations) in the Wall Street Journal is \",text7_len)\n",
        "print(\"The length of words (including punctuations) in the Personal Corpus is \",text8_len)\n",
        "print(\"The length of words (including punctuations) in The Man Who was Thursday is \",text9_len)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x42ajmzYTgHv",
        "outputId": "dcfd32e7-cada-464d-8da8-8e633fe452a8"
      },
      "id": "x42ajmzYTgHv",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of words (including punctuations) in Moby Dick is  260819\n",
            "The length of words (including punctuations) in Sense & Sensibility is  141576\n",
            "The length of words (including punctuations) in the Book of Genesis is  44764\n",
            "The length of words (including punctuations) in the Inaugural Address Corpus is  152901\n",
            "The length of words (including punctuations) in the Chat Corpus is  45010\n",
            "The length of words (including punctuations) in Monty Python and the Holy Grail is  16967\n",
            "The length of words (including punctuations) in the Wall Street Journal is  100676\n",
            "The length of words (including punctuations) in the Personal Corpus is  4867\n",
            "The length of words (including punctuations) in The Man Who was Thursday is  69213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's calculate the normalized frequency of the word \"God\" in our first book, Moby Dick using the formula discussed in Section 2.1.2. In the code below, what we are essentially telling Python is to divide the number of times the word \"God\" appears in Moby Dick (which we had earlier stored in the variable \"a\") by the total number of words in Moby Dick (which we had just stored in the variable \"text1_len\"), and then multiply that by a million. Finally we use another in-built function in Python called \"round\" which rounds the answer off to the nearest whole number. At the end, we save the result in a variable called n_a (short for normalized frequency of a) and then print it."
      ],
      "metadata": {
        "id": "4eiO_uegUicJ"
      },
      "id": "4eiO_uegUicJ"
    },
    {
      "cell_type": "code",
      "source": [
        "#Formula to calculate the normalized frequency of the word \"God\" per 1 million words in the book \"Moby Dick\"\n",
        "n_a = round((a/text1_len)*1000000)\n",
        "print(n_a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64_th_4kX9aV",
        "outputId": "b3680fdc-fe49-4bbc-dcfa-425ed8434ebd"
      },
      "id": "64_th_4kX9aV",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like this, we can now save normalized frequencies of the word \"God\" in all our texts by running the code cell below:"
      ],
      "metadata": {
        "id": "FJCWkR9vbHAQ"
      },
      "id": "FJCWkR9vbHAQ"
    },
    {
      "cell_type": "code",
      "source": [
        "n_a = round((a/text1_len)*1000000)\n",
        "n_b = round((b/text2_len)*1000000)\n",
        "n_c = round((c/text3_len)*1000000)\n",
        "n_d = round((d/text4_len)*1000000)\n",
        "n_e = round((e/text5_len)*1000000)\n",
        "n_f = round((f/text6_len)*1000000)\n",
        "n_g = round((g/text7_len)*1000000)\n",
        "n_h = round((h/text8_len)*1000000)\n",
        "n_i = round((i/text9_len)*1000000)"
      ],
      "metadata": {
        "id": "VgruL88gbF5L"
      },
      "id": "VgruL88gbF5L",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now by running the code cell below, lets print the results from our previous code cell where we found out the normalized frequencies of the word \"God\" in our all texts, by adding some explanatory text that makes the results more readable."
      ],
      "metadata": {
        "id": "efbR7LsBbv3n"
      },
      "id": "efbR7LsBbv3n"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The normalized frequency of the word God in Moby Dick is \", n_a)\n",
        "print(\"The normalized frequency of the word God in Sense and Sensibility is \", n_b)\n",
        "print(\"The normalized frequency of the word God in the Book of Genesis is \", n_c)\n",
        "print(\"The normalized frequency of the word God in the Inaugural Address Corpus is \",n_d)\n",
        "print(\"The normalized frequency of the word God in the Chat Corpus is \",n_e)\n",
        "print(\"The normalized frequency of the word God in Monty Python and the Holy Grail is \",n_f)\n",
        "print(\"The normalized frequency of the word God in the Wall Street Journal is \",n_g)\n",
        "print(\"The normalized frequency of the word God in Personal Corpus is \", n_h)\n",
        "print(\"The normalized frequency of the word God in The Man Who was Thursday is \", n_a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqRurjejbwXM",
        "outputId": "318adb45-7665-43f4-aec2-fd407cdcd238"
      },
      "id": "YqRurjejbwXM",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The normalized frequency of the word God in Moby Dick is  506\n",
            "The normalized frequency of the word God in Sense and Sensibility is  71\n",
            "The normalized frequency of the word God in the Book of Genesis is  5160\n",
            "The normalized frequency of the word God in the Inaugural Address Corpus is  726\n",
            "The normalized frequency of the word God in the Chat Corpus is  22\n",
            "The normalized frequency of the word God in Monty Python and the Holy Grail is  648\n",
            "The normalized frequency of the word God in the Wall Street Journal is  10\n",
            "The normalized frequency of the word God in Personal Corpus is  0\n",
            "The normalized frequency of the word God in The Man Who was Thursday is  506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results that we now have are a lot more robust because we can now more confidently compare them across these texts."
      ],
      "metadata": {
        "id": "5iI7qBB1b_cL"
      },
      "id": "5iI7qBB1b_cL"
    },
    {
      "cell_type": "markdown",
      "id": "d4c807cc-bfe6-4527-891e-15454be5061a",
      "metadata": {
        "id": "d4c807cc-bfe6-4527-891e-15454be5061a"
      },
      "source": [
        "<b> 2.2: Technique Type 2: Data Visualizations </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e48e7d-9bed-47db-82c3-4d38c0753be7",
      "metadata": {
        "id": "b7e48e7d-9bed-47db-82c3-4d38c0753be7"
      },
      "source": [
        "Apart form text-mining results robust, it is also important to make our data and its analysis user-friendly and comprehensible, to enable a wider range of people to infer insights from it. Data visualizations can be very helpful in making that happen! Data Visualizations simply refer to representing data in a way that allows for visual comprehension. This can include using a range of graphs and plots that can help our readers better see patterns in our data that our analysis is trying to reveal.\n",
        "\n",
        "In this notebook, we will learn about two kinds of data visualizations: bar graphs and dispersion plots.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>2.2.1 Bar Graphs</b>\n",
        "\n",
        "<b>What are bar graphs? </b>\n",
        "\n",
        "\n",
        "A bar graph is a simple data visualization that represents the frequency counts of different values that interest us using rectangular shapes. This helps in comparing values across different texts. It can be very powerful in helping us make basic comparisons of frequencies across texts.\n",
        "\n",
        "<b> How can we create bar graphs? </b>\n",
        "\n",
        "Let's try to create a bargraph that will make it easier for us to compare the normalized frequencies we calculated in Section 2.1.2.\n",
        "\n",
        "To create a bar graph, we need to install another Python library apart from NLTK. This is called \"matplotlib\" (Hunter, 2007), a library that helps in creating data visulizations. Run the code cell below to download this library."
      ],
      "metadata": {
        "id": "O9HpWVVfcsYC"
      },
      "id": "O9HpWVVfcsYC"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9f07e039-09b1-4ab9-857d-f448e75f19c3",
      "metadata": {
        "id": "9f07e039-09b1-4ab9-857d-f448e75f19c3"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d0e061-4b62-481b-b173-4ea6d721419c",
      "metadata": {
        "id": "b8d0e061-4b62-481b-b173-4ea6d721419c"
      },
      "source": [
        "Now we need to write code that uses functions from this library to create a simple bar graph to visualize the normalized frequencies we calculated in section 2.1.2.\n",
        "\n",
        "In the code cell below, you will see that we have already written this code for you along with explanations (marked in green and followed by a #)of what each line of code is doing. Try your best to understand what is happening in the code, but keep in mind that it is okay if you do not fully understand each line of code. Towards the end of this notebook, you will find lots of resources that we share which will help you gradually develop that technical understanding over time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "eb93ad88-ce40-431a-b192-4a9799de3f16",
      "metadata": {
        "id": "eb93ad88-ce40-431a-b192-4a9799de3f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "2104d174-b925-4e63-c322-8871d3c57744"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Our goal is here to make a bar graph\n",
        "\n",
        "#We begin by creating an empty visualization canvas called a \"figure\". At this point, there's nothing on the canvas—it's like a blank piece of paper.\n",
        "fig = plt.figure()\n",
        "\n",
        "#Next, on this blank canvas, we want to create an x-y coordinate system (called axes). The list [1,1,1,1] sets the position and size of these axes to form a square shape that fills the entire canvas.\n",
        "ax = fig.add_axes([1,1,1,1])\n",
        "\n",
        "#Next, we give the computer a list of names which will represent the categories or labels on the x-axis of our bar graph.\n",
        "texts = ['Moby', 'Sense', 'Genesis', 'Inaugural', 'Chat','Monty','Wall','Personal','Man']\n",
        "\n",
        "#Next, we tell the computer what values we want each rectangle in our bar graph to represent. We save the values of the normalized frequency counts of the word \"God\" we calculated in Sec 2.1.2\n",
        "frequency = [n_a,n_b,n_c,n_d,n_e,n_f,n_g,n_h,n_i]\n",
        "\n",
        "#Next, we tell the computer that we want it to create a bar-graph using the previously defined x-axis labels (texts) and y-axis values (frequency). In other words, for each name in texts, there's a corresponding bar whose height is determined by the values in frequency.\n",
        "ax.bar(texts,frequency)\n",
        "\n",
        "#In the final step, we simply tell the computer to display our visualization.\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32d34a3d-18d4-4354-9fec-1440d9e0b1da",
      "metadata": {
        "id": "32d34a3d-18d4-4354-9fec-1440d9e0b1da"
      },
      "source": [
        "The code above thus has generated a simple bar graph that displays the frequency counts of the word \"God\" across the 9 textural corpora that we downloaded from NLTK. Each line of code is accompanied by a short explanation marked in green and followed by a \"#\" showing what that line of code does.\n",
        "\n",
        "On looking at the graph, we see here that the word \"God\" appears most frequently in the Book of Genesis. Since the Book of Genesis is a religious book, that makes sense because religious texts usually mention the word God many times. Also, interestingly we see that it appears quite frequently in another book called Moby Dick and the Inaugural Address speeches of American Presidents. But it is quite infrequent in corpora that represent personal writing and web-based chats.\n",
        "\n",
        "<b> What kind of inferences could we draw from such bar graphs? </b>\n",
        "\n",
        "<b> Hint: </b> There can be many inferences that one might draw about what the different frequencies of the word \"God\" reveals to us about these texts and the cultures that they come from. Try to think of categories using which we can diffrentiate between texts in our corpus. What happens when we compare them based on their genre? What happens when we compare them based on their years of publication? What about their cultural contexts? What kind of linguistic, cultural, social inferences can we draw from the results of this basic text-mining?\n",
        "\n",
        "To guide your inferences, you can think of some of the insights that people who've used this resource in workshops conducted by Gupta have come up with. Some people pointed out in certain while the concept of God was very important in classical times, in more recent modern history its relevance has become more varied. While in some social contexts, like in American Presidential speeches, and in existential-spiritual novels like Moby Dick, it remains important in various other contexts of language use like internet chats and news articles, it is not that relevant anymore.\n",
        "\n",
        "Interesting isn't it how visualizing frequencies of words across texts can lead to such insights? Keep in mind though that such inferences aren't meant to be conclusive but rather help us in exploring our data and generate insights that we might want to explore in depth using a combination of other techniques.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe4ff14-04a3-4d3c-b2ab-8c20e863c5a0",
      "metadata": {
        "id": "5fe4ff14-04a3-4d3c-b2ab-8c20e863c5a0"
      },
      "source": [
        "<b> 2.1.2: Dispersion plots </b>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6a07ae-e16a-431f-b92d-e82f90ea27da",
      "metadata": {
        "id": "0c6a07ae-e16a-431f-b92d-e82f90ea27da"
      },
      "source": [
        "<b> What are dispersion plots? </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78a9fe2f-f118-49c5-b266-9c5f4ab05f90",
      "metadata": {
        "id": "78a9fe2f-f118-49c5-b266-9c5f4ab05f90"
      },
      "source": [
        "Dispersion plots can be another very useful type of data visualization in text-mining. As Bird et al., put it well, \"it is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text\" (Bird et al., 2019)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "327d4eb8-1df3-46c0-b7b5-3b9602a90a11",
      "metadata": {
        "id": "327d4eb8-1df3-46c0-b7b5-3b9602a90a11"
      },
      "source": [
        "<b> How can we create a dispersion plot? </b>\n",
        "\n",
        "Dispersion plots work especially well if you are trying to find some insights about how frequencies of a word or set of words has changed over time. Let's use the striking example that Bird et al. (2019) give in their book. They use text4 which contains inaugural addresses given by american presidents over the years arranged in a chronological order (i.e. the first president's speech is present at the beginning of the book and most recent presidents' speech is present at the end of the book). Let's see what their example shows us.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "94dcfadf-3f42-4f2b-93df-7675c7ec72ac",
      "metadata": {
        "id": "94dcfadf-3f42-4f2b-93df-7675c7ec72ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "270270d3-579b-4f33-b05c-2a3bae77de3b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_dispersion_plot(text, word_list):\n",
        "    # Create a list of indices for each word in the word list\n",
        "    indices_list = []\n",
        "    for word in word_list:\n",
        "        indices_list.append([i for i, x in enumerate(text) if x == word])\n",
        "\n",
        "    # Create a scatter plot for each word\n",
        "    for i, word in enumerate(word_list):\n",
        "        plt.scatter(indices_list[i], [word] * len(indices_list[i]), marker='|', color='blue', s=100)\n",
        "\n",
        "    # Set the x-axis limits to show the entire range of the text\n",
        "    plt.xlim(0, len(text))\n",
        "\n",
        "    # Set the y-axis tick labels to the word list\n",
        "    plt.yticks(word_list, fontsize=12)\n",
        "    plt.gca().yaxis.set_tick_params(pad=50) # Add padding between tick labels\n",
        "\n",
        "    # Set the x-axis label and tick labels\n",
        "    plt.xlabel('Character Index', fontsize=12)\n",
        "    plt.xticks(fontsize=12)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "#This function was created with help from ChatGPT\n",
        "\n",
        "# Example usage\n",
        "text = text4\n",
        "word_list = [\"God\",\"freedom\",\"duties\",\"war\"]\n",
        "create_dispersion_plot(text, word_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eb2d3ff-a1b4-4950-b983-0171590acd48",
      "metadata": {
        "id": "8eb2d3ff-a1b4-4950-b983-0171590acd48"
      },
      "source": [
        "This example shows how the frequency of the words \"God\", \"freedom\", \"duties\", \"war\" varies in American presidential speeches over time.\n",
        "\n",
        "<h5> 2.1.3.3 What inferences can we draw from this? </h5>\n",
        "    \n",
        "<b>Hint:</b> What does this tell us about how Presidential priorities have been changing over the decades and how is that a reflection of historical shifts?  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e392de3e-2c01-43f7-bd7a-db79d4502f37",
      "metadata": {
        "id": "e392de3e-2c01-43f7-bd7a-db79d4502f37"
      },
      "source": [
        "<div class = \"alert alert-info\">\n",
        "    \n",
        "Now you try.\n",
        "\n",
        "Try to find create a dispersion plot for text4 i.e. the presidential corpu by replacing \"enter_word1_here\" and \"enter_word2_here\" in the penultimate line of the code below. Choose atleast two words that you think might show any interesting patterns. What insights can we draw from this?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9f9563-16ea-47fc-8ebe-cf0a67fc50af",
      "metadata": {
        "id": "df9f9563-16ea-47fc-8ebe-cf0a67fc50af"
      },
      "outputs": [],
      "source": [
        "def create_dispersion_plot(text, word_list):\n",
        "    # Create a list of indices for each word in the word list\n",
        "    indices_list = []\n",
        "    for word in word_list:\n",
        "        indices_list.append([i for i, x in enumerate(text) if x == word])\n",
        "\n",
        "    # Create a scatter plot for each word\n",
        "    for i, word in enumerate(word_list):\n",
        "        plt.scatter(indices_list[i], [word] * len(indices_list[i]), marker='|', color='blue', s=100)\n",
        "\n",
        "    # Set the x-axis limits to show the entire range of the text\n",
        "    plt.xlim(0, len(text))\n",
        "\n",
        "    # Set the y-axis tick labels to the word list\n",
        "    plt.yticks(word_list, fontsize=12)\n",
        "    plt.gca().yaxis.set_tick_params(pad=50) # Add padding between tick labels\n",
        "\n",
        "    # Set the x-axis label and tick labels\n",
        "    plt.xlabel('Character Index', fontsize=12)\n",
        "    plt.xticks(fontsize=12)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "#This function was created with help from ChatGPT\n",
        "\n",
        "# Example usage\n",
        "text = text4\n",
        "word_list = [\"enter_word1_here\",\"enter_word2_here\"]\n",
        "create_dispersion_plot(text, word_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c1d8b96-897e-45c6-bd13-1c78b1231a8b",
      "metadata": {
        "id": "0c1d8b96-897e-45c6-bd13-1c78b1231a8b"
      },
      "source": [
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "       \n",
        "<h4> 2.1.4: Exploring some iconic studies </h4>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2e786b-44e1-4daf-8fa8-4b2c5b14bbb1",
      "metadata": {
        "id": "aa2e786b-44e1-4daf-8fa8-4b2c5b14bbb1"
      },
      "source": [
        "<b> Good work so far! This very simple technique of counting words that interest us and comparing them across texts can lead to very insightful results. </b>\n",
        "\n",
        "1) Example 1: Let's see a wonderful example of how a researcher did this to map out how corporate organizations did or not did not support the BLM movement on their Twitter profiles, something that could then be used to put pressure on these compabies to support the movement: data and analysis: https://www.kmcelwee.com/fortune-100-blm-report/site/corporate-summaries.html\n",
        "report: https://www.kmcelwee.com/fortune-100-blm-report/site/corporate-summaries.html\n",
        "\n",
        "\n",
        "2) Example 2: Langer et al. (2012) map out how the frequency and diversity of terms that refer to biodiversity has been steadily declining over the last 200 years in Western literature, something that reveals our growing alienation from the natural world https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1002/pan3.10256"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd1ee84-6c21-4da3-9ca4-bdc1a5962c2c",
      "metadata": {
        "id": "bbd1ee84-6c21-4da3-9ca4-bdc1a5962c2c"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "       \n",
        "<h3> 2.2 Technique Type: 2: Close reading (micro-analysis)</h3>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b0e1d9-ef94-4796-8e58-c78f133ee3a2",
      "metadata": {
        "id": "f1b0e1d9-ef94-4796-8e58-c78f133ee3a2"
      },
      "source": [
        "As humanists and social scientists, thankfully we already know that simply knowing quantative differences between the number of times a word appears in two texts, gives us some clues but does not reveal to use a more in-depth picture. This is why, when text-mining researchers usually mix macro readings or distant reading approaches with more micro, qualitative ones to get a more triangulated interpretation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97184779-f9c1-4c85-b61b-569cf3442110",
      "metadata": {
        "id": "97184779-f9c1-4c85-b61b-569cf3442110"
      },
      "source": [
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "<h4> 2.2.1: What are \"condorance lines\"? </h4>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdec5994-fe8a-4081-a2dd-dfe41a0499e8",
      "metadata": {
        "id": "cdec5994-fe8a-4081-a2dd-dfe41a0499e8"
      },
      "source": [
        "Concordance lines are simply \"a list of all the occurences of a particular search term in a corpus, presented within the context in which they occur; usually a few words to the left and right of the search term\" (Baker, 2006: 71)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4772b6c1-8491-44fa-9704-7ac7f95d0ecd",
      "metadata": {
        "id": "4772b6c1-8491-44fa-9704-7ac7f95d0ecd"
      },
      "source": [
        "<h5> 2.2.1.1: Visualizing concordance lines </h5>\n",
        "\n",
        "The NLTK Library has an in-built function we can use to see concordance lines of key terms that interest us\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fdb445e-30ee-4d80-ad9f-7a074615cc35",
      "metadata": {
        "id": "3fdb445e-30ee-4d80-ad9f-7a074615cc35"
      },
      "outputs": [],
      "source": [
        "text3.concordance(\"woman\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c83fe3-d01b-48c9-907a-ce3fef12c32d",
      "metadata": {
        "id": "44c83fe3-d01b-48c9-907a-ce3fef12c32d"
      },
      "source": [
        "As you can see, this function \"concordance\" displays the word we are interested in (here \"woman\" for an example) in a text of our choice (here, text 3 or book of genesis for example) along with a small slice of the sentences in which that word appears in that text. This allows us to see the semantic context in which our word appears which can be helpful for close-reading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a99312d-9298-4a86-bf7f-093feb906a1b",
      "metadata": {
        "id": "4a99312d-9298-4a86-bf7f-093feb906a1b"
      },
      "source": [
        "<h5> 2.2.1.2: Using concordances to explore our \"God\" inferences </h5>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e88290b-eba0-49c8-9759-543d4cf9de89",
      "metadata": {
        "id": "6e88290b-eba0-49c8-9759-543d4cf9de89"
      },
      "source": [
        "<b> Remember the inference you drew earlier based on the frequencies of \"God\" in these texts? Let's now try to gain a more in-depth understanding of it using some close-reading or micro analysis techniques </b>\n",
        "\n",
        "Let's say that hypothetically, an inference you drew was that the influence of the concept of \"God\" in Western human imagination is reducing over time. While in ancient texts like the Book of Genesis, it is quite high, as we come to more modern texts, its frequency starts to become low. However, in certain genres, like American presidential speeches or existential texts like Moby Dick, it is still relatively high, but in other genres like web-chats or newspaper advertisements it is almost non-existent.\n",
        "\n",
        "<b> Let's now look at some concordance lines to see what contexts the word \"God\" appears in in these texts </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1dddd8-304f-445a-83d5-e85c05b82b59",
      "metadata": {
        "id": "cf1dddd8-304f-445a-83d5-e85c05b82b59"
      },
      "source": [
        "Let's first see how it appears in Moby Dick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5ee051-3293-4a9b-b44d-d222311709eb",
      "metadata": {
        "id": "9c5ee051-3293-4a9b-b44d-d222311709eb"
      },
      "outputs": [],
      "source": [
        "text1.concordance(\"God\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ca8aed-883b-4531-9713-e150ad680cbe",
      "metadata": {
        "id": "48ca8aed-883b-4531-9713-e150ad680cbe"
      },
      "source": [
        "<div class = \"alert alert-info\">\n",
        "    \n",
        "<b>Now you try. </b>\n",
        "\n",
        "Try to display concordance lines that contain the word \"God\" in a text of your choice from the corpus that we have been using\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1ec651-05df-4f32-adeb-4b6d2939ef55",
      "metadata": {
        "id": "8f1ec651-05df-4f32-adeb-4b6d2939ef55"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "466e2e8e-6e96-4fbd-a375-6ca6cd489237",
      "metadata": {
        "id": "466e2e8e-6e96-4fbd-a375-6ca6cd489237"
      },
      "source": [
        "<h5> 2.2.1.3: What new inferences can you draw based on such comparison?</h5>\n",
        "\n",
        "<b>Hint:</b> Focus on the difference in the context in which the word \"God\" is used in your texts of choice. Many insights are possible. You could maybe focus on the grammatical categories of the word \"God\". Has it been used as a proper noun or a common noun? What kind of tone does the sentence have where it has been used? It is very formal and reverential. Or is it more informal and irreverant? What words (nouns, adjectives, verbs etc.) appear usually near it? What do these differences tell us about the cultures and historical moments in which these texts appear?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a4a359-bcf8-4c1e-a978-96c74d1a7f41",
      "metadata": {
        "id": "36a4a359-bcf8-4c1e-a978-96c74d1a7f41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "29657589-ce6d-4430-b356-ccb096603a20",
      "metadata": {
        "id": "29657589-ce6d-4430-b356-ccb096603a20"
      },
      "source": [
        "***\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "       \n",
        "<h4> 2.2.2: Collocates Analysis</h4>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be75c081-3989-4fa4-8bbf-4bbb72d12027",
      "metadata": {
        "id": "be75c081-3989-4fa4-8bbf-4bbb72d12027"
      },
      "source": [
        "<h5> 2.2.2.1 What are collocates? </h5>\n",
        "\n",
        "<p>\n",
        "\n",
        "\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8423d676-2b14-409d-b463-64614c17526b",
      "metadata": {
        "id": "8423d676-2b14-409d-b463-64614c17526b"
      },
      "source": [
        "Another very useful technique for micro-anlaysis or close-reading is called collocates analysis. \"When a word regularly appears near another word and the relationship is statistically significant in some way, then such co-occurences are referred to as collocates and the phenomena of certain words frequently occuring next to or near each other is called collocation\" (Baker, 2006: 96). This can be especially useful in discourse anlaysis when we are trying to find out how certain words or concepts are understood within a text, or within a corpus of texts that represent a particular socio-historical or cultural moment. For example, if we look at a global news corpus, the word \"states\" would appear as an important collocate of the word \"united\", because the word \"united states\" would appear quite frequently in it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5071dbc2-2fa2-422b-9c57-faf01e61307e",
      "metadata": {
        "id": "5071dbc2-2fa2-422b-9c57-faf01e61307e"
      },
      "source": [
        "<h5> 2.2.2.2 Finding collocates </h5>\n",
        "<h8>All the code snippets below for finding collocates were created with help from Saba (2022)'s code and ChatGPT</h8>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c2ea2cf-1918-42a9-a017-83c25bec9d79",
      "metadata": {
        "id": "7c2ea2cf-1918-42a9-a017-83c25bec9d79"
      },
      "source": [
        "Now finding collocates is a slightly more complicated procedure as it involves some slightly complicated statistics and computer programming. But thankfully, due to the beauty of Python, we can use code that other people have written. As beginners trying to understand these methods, it is okay to not understand how these procedures are leading to the outputs we are getting, but as you go more in-depth, it is helpful to learn about the intracies of these methods to see how they impact our results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec390c13-e5ae-421f-ae22-a750345f7e1a",
      "metadata": {
        "id": "ec390c13-e5ae-421f-ae22-a750345f7e1a"
      },
      "source": [
        "<h5> 2.2.2.3 \"God\" in Amerian Presidential Speeches </h5>\n",
        "    \n",
        "The code below finds the most significant 2-word collocates for a word we choose in text4: presidential inaugural address corpus. Here I have tweaked this code to show us the collocates of the word \"God\". This code also shows us a simple visualization to help us process the results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c6f270",
      "metadata": {
        "id": "50c6f270"
      },
      "source": [
        "<h5> 2.2.2.1 Bigram collocates </h5>\n",
        "    \n",
        "The code below finds the most significant 2-word collocates for a word we choose in text4: presidential inaugural address corpus. Here I have tweaked this code to show us the collocates of the word \"God\". This code also shows us a simple visualization to help us process the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98219fff-58b2-45fe-b1c1-4cb85f576078",
      "metadata": {
        "id": "98219fff-58b2-45fe-b1c1-4cb85f576078"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.probability import FreqDist\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load text and preprocess it\n",
        "text4 = nltk.corpus.inaugural.raw()\n",
        "text4_processed = nltk.Text([word.lower() for word in nltk.word_tokenize(text4) if word not in string.punctuation])\n",
        "\n",
        "# Find top 10 bigrams that contain 'God'\n",
        "finder = BigramCollocationFinder.from_words(text4_processed)\n",
        "finder.apply_ngram_filter(lambda w1, w2: 'god' not in (w1, w2))\n",
        "bigram_list = finder.nbest(nltk.collocations.BigramAssocMeasures().raw_freq, 10)\n",
        "\n",
        "# Get frequency distribution of each bigram in text4\n",
        "fdist = FreqDist(bigram for bigram in nltk.bigrams(text4_processed))\n",
        "bigram_count = [fdist[bigram] for bigram in bigram_list]\n",
        "\n",
        "# Create a bar chart of the bigram counts\n",
        "plt.bar(range(len(bigram_list)), bigram_count)\n",
        "plt.xticks(range(len(bigram_list)), bigram_list, rotation=45)\n",
        "plt.xlabel('Bigram')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 10 Bigrams Containing \"God\" in Inaugural Addresses')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc79e6b-e16f-4307-906b-2e4ff945e48a",
      "metadata": {
        "id": "edc79e6b-e16f-4307-906b-2e4ff945e48a"
      },
      "source": [
        "<h5> 2.2.2.1.1 How to read this output </h5>\n",
        "\n",
        "What we see now is a list of collocates of the word \"God\" in text1. In each bracket, you see one or more words along with the word \"God\" which are its collocates. For example, in the bracket ('God','bless'), the verb \"bless\" is a collocate or a word that appears quite frequently on the right of the noun \"God\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "418be152",
      "metadata": {
        "id": "418be152"
      },
      "source": [
        "<h5> 2.2.2.2 Tri-gram collocates </h5>\n",
        "    \n",
        "Let's do the same now for 3-word collocates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01429b24",
      "metadata": {
        "id": "01429b24"
      },
      "outputs": [],
      "source": [
        "#Load relevant functions\n",
        "from nltk.collocations import TrigramCollocationFinder\n",
        "\n",
        "# Load text and preprocess it\n",
        "text4 = nltk.corpus.inaugural.raw()\n",
        "text4_processed = nltk.Text([word.lower() for word in nltk.word_tokenize(text4) if word not in string.punctuation])\n",
        "\n",
        "# Find top 10 trigrams that contain 'God'\n",
        "finder = TrigramCollocationFinder.from_words(text4_processed)\n",
        "finder.apply_ngram_filter(lambda w1, w2, w3: 'god' not in (w1, w2, w3))\n",
        "trigram_list = finder.nbest(nltk.collocations.TrigramAssocMeasures().raw_freq, 10)\n",
        "\n",
        "# Get frequency distribution of each trigram in text4\n",
        "fdist = FreqDist(trigram for trigram in nltk.trigrams(text4_processed))\n",
        "trigram_count = [fdist[trigram] for trigram in trigram_list]\n",
        "\n",
        "# Create a bar chart of the trigram counts\n",
        "plt.bar(range(len(trigram_list)), trigram_count)\n",
        "plt.xticks(range(len(trigram_list)), trigram_list, rotation=45)\n",
        "plt.xlabel('Trigram')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 10 Trigrams Containing \"God\" in Inaugural Addresses')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760ca7bd",
      "metadata": {
        "id": "760ca7bd"
      },
      "source": [
        "<h5> 2.2.2.3 Quad-gram collocates </h5>\n",
        "    \n",
        "Let's do the same now for 4-word collocates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b9a9e5",
      "metadata": {
        "id": "a8b9a9e5"
      },
      "outputs": [],
      "source": [
        "#Load relevant functions\n",
        "from nltk.collocations import QuadgramCollocationFinder\n",
        "\n",
        "# Load text and preprocess it\n",
        "text = nltk.corpus.inaugural.raw()\n",
        "text_processed = nltk.Text([word.lower() for word in nltk.word_tokenize(text) if word not in string.punctuation])\n",
        "\n",
        "# Find top 10 quadgrams that contain 'america'\n",
        "finder = QuadgramCollocationFinder.from_words(text_processed)\n",
        "finder.apply_ngram_filter(lambda w1, w2, w3, w4: 'God' not in (w1, w2, w3, w4))\n",
        "quadgram_list = finder.nbest(nltk.collocations.QuadgramAssocMeasures().raw_freq, 10)\n",
        "\n",
        "# Get frequency distribution of each quadgram in text\n",
        "fdist = FreqDist(quadgram for quadgram in nltk.ngrams(text_processed, 4))\n",
        "quadgram_count = [fdist[quadgram] for quadgram in quadgram_list]\n",
        "\n",
        "# Create a bar chart of the quadgram counts\n",
        "plt.bar(range(len(quadgram_list)), quadgram_count)\n",
        "plt.xticks(range(len(quadgram_list)), quadgram_list, rotation=45)\n",
        "plt.xlabel('Quadgram')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 10 Quadgrams Containing \"America\" in Inaugural Addresses')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91d05b32-d4e8-4921-af89-76d9b6f504fe",
      "metadata": {
        "id": "91d05b32-d4e8-4921-af89-76d9b6f504fe"
      },
      "source": [
        "<h5> 2.2.2.5: What inference can we draw from this? </h5>\n",
        "\n",
        "<b> Hint:</b> Think about what the frequent use of the verb \"bless\" next to the noun \"God\" tells us about how American presidents frame the concept of \"God\" discursively or rhetorically in their speeches?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17cbfd8-a4a3-4804-80cf-030a286abe4e",
      "metadata": {
        "id": "e17cbfd8-a4a3-4804-80cf-030a286abe4e"
      },
      "source": [
        "<div class = \"alert alert-info\">\n",
        "    \n",
        "Now you try.\n",
        "\n",
        "In the code below, just change the word \"enter_word_here\" wherever it appears with a word whose collocates you want to explore in the inaugural address corpus and then run the cell.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9098293-3784-4745-ac3b-dc1a8ac1d3b8",
      "metadata": {
        "id": "e9098293-3784-4745-ac3b-dc1a8ac1d3b8"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "from nltk.probability import FreqDist\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load text and preprocess it\n",
        "text4 = nltk.corpus.inaugural.raw()\n",
        "text4_processed = nltk.Text([word.lower() for word in nltk.word_tokenize(text4) if word not in string.punctuation])\n",
        "\n",
        "# Find top 10 bigrams that contain 'God'\n",
        "finder = BigramCollocationFinder.from_words(text4_processed)\n",
        "finder.apply_ngram_filter(lambda w1, w2: 'enter_word_here' not in (w1, w2))\n",
        "bigram_list = finder.nbest(nltk.collocations.BigramAssocMeasures().raw_freq, 10)\n",
        "\n",
        "# Get frequency distribution of each bigram in text4\n",
        "fdist = FreqDist(bigram for bigram in nltk.bigrams(text4_processed))\n",
        "bigram_count = [fdist[bigram] for bigram in bigram_list]\n",
        "\n",
        "# Create a bar chart of the bigram counts\n",
        "plt.bar(range(len(bigram_list)), bigram_count)\n",
        "plt.xticks(range(len(bigram_list)), bigram_list, rotation=45)\n",
        "plt.xlabel('Bigram')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 10 Bigrams Containing \"enter_word_here\" in Inaugural Addresses')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733b41b9-fd74-489c-b2af-5ca6197446d3",
      "metadata": {
        "id": "733b41b9-fd74-489c-b2af-5ca6197446d3"
      },
      "source": [
        "What does this output tell you about how your word of choice has been discursively or rhetorically framed within this corpus of texts?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dddc7396-7d70-4304-92ea-ac83965d1859",
      "metadata": {
        "id": "dddc7396-7d70-4304-92ea-ac83965d1859"
      },
      "source": [
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "       \n",
        "<h4> 2.2.3: Exploring some iconic studies </h4>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8828d56c-8a96-4f5d-9e13-4818fe505dc4",
      "metadata": {
        "id": "8828d56c-8a96-4f5d-9e13-4818fe505dc4"
      },
      "source": [
        "<b> Good work so far! Let's explore some iconic studies now that use these techniques </b>\n",
        "\n",
        "1) Example 1: Gabrielatos & Baker (2008) analyse a huge corpus of newspapers in the UK to see what kind of collocates they commonly use to refer to refugees and asylum seekers, and they find consistent patterns like metaphors of \"water\" used to construct refugees (e.g. \"refugees are flooding the country\") to create a cognitive frame whereby the public thinks of them as a natural disaster which is plaguing their country: https://journals.sagepub.com/doi/abs/10.1177/0075424207311247\n",
        "\n",
        "2) Example 2: Thomas and Droge (2022) analyse a huge corpus of newspapers in the US to see what kind of topics are commonly used whenever the word \"Humanities\" is referred to. They use a Machine Learning technique called topic modelling which is like a fancier version of collocates analysis. They find that instead of Humanities bein referred to only in terms of \"crisis\", which is what academics believe is the public discourse around this discipline, there are a range of interesting topics that are prevalent. Let's explore their findings here: https://we1s.ucsb.edu/research/we1s-findings/key-findings/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd44e2b2-8301-4510-a44c-b6e724c1c2ae",
      "metadata": {
        "id": "dd44e2b2-8301-4510-a44c-b6e724c1c2ae"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    <h1> Part 3: Applying to your work </h1>\n",
        "\n",
        "\n",
        "<b> How do you think some of these techniques might apply to your work? </b>\n",
        "    \n",
        "<b>Some suggestions:</b>\n",
        "    \n",
        "<u>1. Play around with existing corpora and textual datasets: </u>\n",
        "\n",
        "https://www.kaggle.com/datasets\n",
        "    \n",
        "https://crow.corporaproject.org/\n",
        "\n",
        "https://elicorpora.info/main\n",
        "    \n",
        "https://dataverse.harvard.edu/dataverse/gwu-libraries\n",
        "    \n",
        "https://catalog.docnow.io/\n",
        "    \n",
        "<u> 2. Build your own corpus of texts: </u>\n",
        "    \n",
        "https://writecrow.org/ciabatta/\n",
        "    \n",
        "<u> 3. Read journals that publish research with text mining techniques for Humanities/Social Sciences </u>\n",
        "    \n",
        "Journal of Cultural Analytics: https://culturalanalytics.org/issues  \n",
        "    \n",
        "Digital Humanities Quarterly: http://digitalhumanities.org/dhq/\n",
        "    \n",
        "Journal of Writing Analytics:  \n",
        "\n",
        "<u> 4. Web resoures with beginner friendly lessons on text-mining </u>\n",
        "    \n",
        "Where to start with text mining by Ted Underwood:https://tedunderwood.com/2012/08/14/where-to-start-with-text-mining/\n",
        "    \n",
        "University of Arizona Library's Guide to Text-Mining: https://libguides.library.arizona.edu/text-mining\n",
        "    \n",
        "JSTOR's Text Analysis Pedagogy Institute's Resources: https://labs.jstor.org/projects/text-analysis-pedagogy-institute-2/\n",
        "    \n",
        "Introduction to Cultural Analytics & Python: https://melaniewalsh.github.io/Intro-Cultural-Analytics/welcome.html\n",
        "    \n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0bd2c1e-180c-4ae5-b7a8-801c90b70445",
      "metadata": {
        "id": "f0bd2c1e-180c-4ae5-b7a8-801c90b70445"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    <h1> Feedback </h1>\n",
        "\n",
        "<p>\n",
        "\n",
        "To help me improve the design of this workshop, please fill out this short feedback survey. It will take 3-4 minutes: https://forms.gle/NzVpUdCx8KqHauL36\n",
        "    </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "904ee42d-6c0b-4a83-ad50-dc58838be157",
      "metadata": {
        "id": "904ee42d-6c0b-4a83-ad50-dc58838be157"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "<h2> Acknowledgements</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd09fc73-d324-4961-a404-6db406b8f8ea",
      "metadata": {
        "id": "dd09fc73-d324-4961-a404-6db406b8f8ea"
      },
      "source": [
        "1. This resource was developed as part of the Workshop Series from the Digital Scholarship and Data Science Fellowship Program funded by the University Libraries at the University of Arizona. You can learn more about this program by clicking here: https://data.library.arizona.edu/data-science/ds2f\n",
        "\n",
        "2. I'm grateful to Jeffrey Oliver and Megan Senseney for their inspiring mentorship and well-scaffolded year long training program that helped me produce this resource. I'm also thankful to Jim Martin, Yvonne Mery, Leslie Sult, and Cheryl Casey for their insightful lectures on various aspects of data science, digital pedagogy, and open educatioanl resource production.\n",
        "\n",
        "3. I'm especially thankfully to Prof. Charlie Gomez and his amazing class INFO 514: Computational Social Science at the University of Arizona. A lot of the content for this notebook, especially the introduction to Jupypter Notebooks as well as the markdown code for this notebook have been adapted, with permission, from his class notebooks. If you are a University of Arizona student interested in learning these skills, I strongly recommend taking this class or auditing it.\n",
        "\n",
        "4. I'm extremely grateful to Prof. Shelley Staples and Mark Fuller at the CROW Lab with whom I did an indepdent study during Spring 2022 and learnt the ropes of text mining and corpus linguistics.\n",
        "\n",
        "5. I would also like to thank the RCTE Program and its faculty who created the Immersive Cultural Requirement (ICR) for PhD students which requires them to immerse themselves in a culture, learn new skills and reciprocate. That programmatic requirement encouraged me to immerse myself in the text-mining community, learn coding, and am now trying to reciprocate through such resources and workshops.\n",
        "\n",
        "6. I'm also grateful to JSTOR's TAPI summer institute, University of Birmingham's Corpus Linguistics summer institute, and the ISTA 130: Introduction to Computational Thinking class at the University of Arizona, all avenues where I learnt a lot of text-mining skills.\n",
        "\n",
        "7. I'm also grateful to ChatGPT for helping me debug some of my code.\n",
        "\n",
        "8. Last but not the least, I want to also acknowledge the amazing coding community online on Github, Stackoverflow, and Youtube who are so generous with sharing resources and helping out beginners through threads and discussions. The academic world could really benefit a lot from following the open-sourced and compassionate nature of knowledge building that these communities follow online."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "326dcde4-354e-4489-b396-ff495b740aa4",
      "metadata": {
        "id": "326dcde4-354e-4489-b396-ff495b740aa4"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "<h2> Works Cited</h2>\n",
        "   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80f25608-5c9d-4cfc-9508-e01584fa460a",
      "metadata": {
        "id": "80f25608-5c9d-4cfc-9508-e01584fa460a"
      },
      "source": [
        "1. ACLS. (2006). Our Cultural Commonwealth: The report of the American Council of Learned Societies Commission on Cyberinfrastructure for the Humanities and Social Sciences. ACLS. https://www.ideals.illinois.edu/items/199 <br>\n",
        "    \n",
        "2. Evans, J. A., & Aceves, P. (2016). Machine Translation: Mining Text for Social Theory. Annual Review of Sociology, 42(1), 21–50. https://doi.org/10.1146/annurev-soc-081715-074206<br>\n",
        "    \n",
        "3. Bird, Steven, Ewan Klein, and Edward Loper (2009), Natural Language Processing with Python, O'Reilly Media.<br>\n",
        "    \n",
        "4. Baker, P. (2006). Using corpora in discourse analysis. Continuum.\n",
        "\n",
        "5. Gabrielatos, C., & Baker, P. (2008). Fleeing, Sneaking, Flooding: A Corpus Analysis of Discursive Constructions of Refugees and Asylum Seekers in the UK Press, 1996-2005. Journal of English Linguistics, 36(1), 5–38. https://doi.org/10.1177/0075424207311247\n",
        "\n",
        "\n",
        "6. Harris, C.R., Millman, K.J., van der Walt, S.J. et al. Array programming with NumPy. Nature 585, 357–362 (2020). DOI: 10.1038/s41586-020-2649-2. (Publisher link)\n",
        "\n",
        "7. Jänicke, S., Franzini, G., Cheema, M. F., & Scheuermann, G. (2015). On Close and Distant Reading in Digital Humanities: A Survey and Future Challenges. Eurographics Conference on Visualization, 21.\n",
        "\n",
        "8. J. D. Hunter, \"Matplotlib: A 2D Graphics Environment\", Computing in Science & Engineering, vol. 9, no. 3, pp. 90-95, 2007.\n",
        "\n",
        "9. Langer, L., Burghardt, M., Borgards, R., Böhning‐Gaese, K., Seppelt, R., & Wirth, C. (2021). The rise and fall of biodiversity in literature: A comprehensive quantification of historical changes in the use of vernacular labels for biological taxa in Western creative literature. People and Nature, 3(5), 1093–1109. https://doi.org/10.1002/pan3.10256\n",
        "\n",
        "10. McElwee. (2021). The Fortune 100 & Black Lives Matter. Kmcelwee. https://www.kmcelwee.com/fortune-100-blm-report/site/corporate-summaries.html\n",
        "\n",
        "\n",
        "11. Sabba. (2022). NLTK collocations for specific words. https://9to5answer.com/nltk-collocations-for-specific-words\n",
        "\n",
        "12. Schreiber, J., & Melon�on, L. (Eds.). (2022). Assembling Critical Components: A Framework for Sustaining Technical and Professional Communication. The WAC Clearinghouse; University Press of Colorado. https://doi.org/10.37514/TPC-B.2022.1381\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae83fe70-b648-419c-833e-4c1ba6e22182",
      "metadata": {
        "id": "ae83fe70-b648-419c-833e-4c1ba6e22182"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "<h2> Copyright information </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec25394-8dbc-45e2-9cea-6c5f0885fb98",
      "metadata": {
        "id": "aec25394-8dbc-45e2-9cea-6c5f0885fb98"
      },
      "source": [
        "Shield: [![CC BY 4.0][cc-by-shield]][cc-by]\n",
        "\n",
        "This work is licensed to Anuj Gupta under a\n",
        "[Creative Commons Attribution 4.0 International License][cc-by].\n",
        "\n",
        "[![CC BY 4.0][cc-by-image]][cc-by]\n",
        "\n",
        "[cc-by]: http://creativecommons.org/licenses/by/4.0/\n",
        "[cc-by-image]: https://i.creativecommons.org/l/by/4.0/88x31.png\n",
        "[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}